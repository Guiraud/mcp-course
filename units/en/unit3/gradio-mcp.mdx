# Hugging Face Gradio MCP Integration

Hugging Face's Gradio framework offers a powerful way to build and deploy web interfaces for AI applications. With its MCP integration, Gradio now makes it easier than ever to create interactive interfaces for MCP-enabled AI systems as well as building MCP servers in just a few lines of code.

## What is Gradio MCP?

Gradio MCP is an extension of the popular Gradio framework that allows developers to:

1. Create web interfaces for MCP-enabled applications with minimal code
2. Build MCP servers that can be used by any MCP client (like Claude, Cursor, or Cline)
3. Visualize and debug MCP interactions through a user-friendly interface
4. Deploy MCP applications to the Hugging Face Spaces platform with a single click
5. Share MCP capabilities with others through an intuitive UI

This integration bridges the gap between powerful MCP functionality and accessible user interfaces, making MCP-enabled AI systems more usable and shareable.

## Building an MCP Server with Gradio

According to the [official Hugging Face blog post](https://huggingface.co/blog/gradio-mcp), turning any Gradio app into an MCP server is remarkably simple. Here's how:

### Installation

First, install Gradio with the MCP extra:

```bash
pip install "gradio[mcp]"
```

### Creating a Simple MCP Server

Here's an example of a letter-counting tool exposed as an MCP server:

```python
import gradio as gr

def letter_counter(word, letter):
    """Count the occurrences of a specific letter in a word.
    
    Args:
        word: The word or phrase to analyze
        letter: The letter to count occurrences of
        
    Returns:
        The number of times the letter appears in the word
    """
    return word.lower().count(letter.lower())

demo = gr.Interface(
    fn=letter_counter,
    inputs=["text", "text"],
    outputs="number",
    title="Letter Counter",
    description="Count how many times a letter appears in a word"
)

demo.launch(mcp_server=True)
```

That's it! The only addition is the `mcp_server=True` parameter in the `launch()` method. When you run this app, it will:

1. Start the regular Gradio web interface
2. Start the MCP server
3. Print the MCP server URL in the console

### How Gradio MCP Works

Gradio automatically converts your Python functions into MCP tools that can be used by LLMs. The docstring of your function is used to generate the description of the tool and its parameters, making it seamless to expose functionality to MCP clients.

The MCP server will be accessible at:
```
http://your-server:port/gradio_api/mcp/sse
```

To use this server with an MCP client (like Claude Desktop, Cursor, or Cline), you simply need to add this URL to your client's configuration:

```json
{
  "mcpServers": {
    "gradio": {
      "url": "http://your-server:port/gradio_api/mcp/sse"
    }
  }
}
```

## Key Features of Gradio MCP

### Tool Conversion

Each API endpoint in your Gradio app is automatically converted into an MCP tool with a corresponding name, description, and input schema. To view the available tools and their schemas, you can visit:
```
http://your-server:port/gradio_api/mcp/schema
```

Or go to the "View API" link in the footer of your Gradio app and click on "MCP".

### Environment Variable Support

There are two ways to enable MCP server functionality:

1. Using the `mcp_server` parameter as shown above:
   ```python
   demo.launch(mcp_server=True)
   ```

2. Using environment variables:
   ```bash
   export GRADIO_MCP_SERVER=True
   ```

### File Handling

The server automatically handles file data conversions, including:
- Converting base64-encoded strings to file data
- Processing image files and returning them in the correct format
- Managing temporary file storage

It is strongly recommended to pass input images and files as full URLs ("http://..." or "https://...") as MCP clients do not always handle local files correctly.

### Hosted MCP Servers on Hugging Face Spaces

You can publish your Gradio application for free on Hugging Face Spaces, which will give you a free hosted MCP server. This allows you to share your MCP tools with others easily.

For example, you can try out the MCP tools from [this Space](https://huggingface.co/spaces/abidlabs/mcp-tools) by adding the following configuration to your MCP client:

```json
{
  "mcpServers": {
    "gradio": {
      "url": "https://abidlabs-mcp-tools.hf.space/gradio_api/mcp/sse"
    }
  }
}
```

## Advanced Usage

### Multiple Tools in One Server

You can expose multiple tools from a single Gradio app:

```python
import gradio as gr

def add(a, b):
    """Add two numbers together.
    
    Args:
        a: The first number
        b: The second number
        
    Returns:
        The sum of the two numbers
    """
    return a + b

def multiply(a, b):
    """Multiply two numbers together.
    
    Args:
        a: The first number
        b: The second number
        
    Returns:
        The product of the two numbers
    """
    return a * b

demo = gr.Blocks()

with demo:
    with gr.Tab("Addition"):
        a1 = gr.Number()
        b1 = gr.Number()
        output1 = gr.Number()
        gr.Interface(fn=add, inputs=[a1, b1], outputs=output1)
    
    with gr.Tab("Multiplication"):
        a2 = gr.Number()
        b2 = gr.Number()
        output2 = gr.Number()
        gr.Interface(fn=multiply, inputs=[a2, b2], outputs=output2)

demo.launch(mcp_server=True)
```

This will expose both the `add` and `multiply` functions as separate MCP tools.

### Client Integration

Gradio can also serve as an MCP client, allowing you to create interfaces that connect to MCP servers. This will be covered in more detail in our hub-mcp-servers section.

## Example Projects

Hugging Face hosts several example projects demonstrating Gradio MCP integration:

1. **[MCP Tools Demo](https://huggingface.co/spaces/abidlabs/mcp-tools)**: A collection of useful MCP tools built with Gradio
2. **[Kokoro MCP](https://huggingface.co/spaces/fdaudens/kokoro-mcp)**: A text-to-speech application exposed as an MCP server
3. **MCP Multi-Tool Demo**: Showcases multiple MCP servers working together in a single interface

These examples provide excellent starting points for your own Gradio MCP applications.

## Best Practices

When building with Gradio MCP, consider these best practices:

1. **Provide Clear Documentation**: Use detailed docstrings to help LLMs understand how to use your tools
2. **Use Type Hints**: Add Python type hints to your functions to help Gradio generate accurate schemas
3. **Error Handling**: Implement robust error handling to provide helpful feedback
4. **Consider Statelessness**: Design your tools to be stateless when possible
5. **Security Considerations**: Be mindful of tool permissions, especially in shared deployments

By following these practices, you can create robust, user-friendly MCP applications using Gradio that seamlessly integrate with LLM applications.

In the next section, we'll explore working with MCP servers on the Hugging Face Hub. 